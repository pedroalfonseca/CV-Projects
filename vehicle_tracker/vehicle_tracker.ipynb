{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Vehicle Tracker_\n",
    "This application reads a video of a highway traffic, defines a region of interest and tracks objects in drastic movement (vehicles, in this case) while also assigning them an ID, according to the order in which they appear. I made this mainly with the intention of taking my first steps with Computer Vision and OpenCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "The only ones needed are _hypot_, a function from the _math_ module that computes the multidimensional euclidean distance from the origin to a point, and _cv2_, the module import name for _opencv-python_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroid Tracker\n",
    "In the used video, multiple objects are often detected in consecutive frames and need to be associated across frames. Therefore, for consistent tracking of objects over time, we can create a class that, using the centroids of the bounding boxes, determines whether an object in the current frame corresponds to an existing tracked object or is a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker:\n",
    "    def __init__(self):\n",
    "        self.centroids = {}\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, boxes, threshold):\n",
    "        box_ids = []\n",
    "\n",
    "        for x, y, w, h in boxes:\n",
    "            c_x = (2 * x + w) // 2\n",
    "            c_y = (2 * y + h) // 2\n",
    "\n",
    "            same_object = False\n",
    "            for id, pt in self.centroids.items():\n",
    "                dist = hypot(c_x - pt[0], c_y - pt[1])\n",
    "                if dist < threshold:\n",
    "                    self.centroids[id] = (c_x, c_y)\n",
    "                    box_ids.append([x, y, w, h, id])\n",
    "                    same_object = True\n",
    "                    break\n",
    "\n",
    "            if same_object is False:\n",
    "                self.centroids[self.id_count] = (c_x, c_y)\n",
    "                box_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        new_centroids = {}\n",
    "        for _, _, _, _, id in box_ids:\n",
    "            new_centroids[id] = self.centroids[id]\n",
    "\n",
    "        self.centroids = new_centroids.copy()\n",
    "\n",
    "        return box_ids\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "These 3 global variables are declared outside the main loop to then be used within it:\n",
    "- `capture`: reads the frames of `traffic.mp4` during the subsequent processing.\n",
    "- `detector`: executes the _Gaussian Mixture-based Background/Foreground Segmentation_ algorithm.\n",
    "- `tracker`: associates bounding boxes and unique IDs to objects detected in the subsequently processed video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(\"traffic.mp4\")\n",
    "detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=60)\n",
    "tracker = CentroidTracker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop\n",
    "The operation of the application consists of the following steps:\n",
    "1. Reading frames from a video\n",
    "2. Defining a region of interest (ROI)\n",
    "3. Performing background subtraction and object detection within the defined ROI\n",
    "4. Associating detected objects with existing tracked objects\n",
    "5. Visualizing the results by displaying the processed frames with bounding boxes and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Step 1\n",
    "    _, frame = capture.read()\n",
    "\n",
    "    # Step 2\n",
    "    roi = frame[260:, :660]\n",
    "\n",
    "    # Step 3\n",
    "    detections = []\n",
    "    mask = detector.apply(roi)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 100:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            detections.append([x, y, w, h])\n",
    "\n",
    "    # Step 4\n",
    "    box_ids = tracker.update(detections, 25)\n",
    "    for x, y, w, h, id in box_ids:\n",
    "        cv2.putText(\n",
    "            roi,\n",
    "            f\"Vehicle #{id}\",\n",
    "            (x, y - 15),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "\n",
    "    # Step 5\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
